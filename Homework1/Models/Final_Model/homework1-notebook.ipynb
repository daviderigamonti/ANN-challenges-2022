{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Importing libraries","metadata":{}},{"cell_type":"code","source":"import os\nimport random\nimport tensorflow as tf\nimport numpy as np\nimport pandas as pd\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\n\nfrom sklearn.metrics import classification_report\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\ntfk = tf.keras\ntfkl = tf.keras.layers\nprint(tf.__version__)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Defining variables","metadata":{}},{"cell_type":"code","source":"dataset_dir = '/kaggle/input/homework1/training_data_final'\nsubmodels_dir = '/kaggle/input/ann_homework1_ensemble'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Random seed for reproducibility\nseed = 42\n\nrandom.seed(seed)\nnp.random.seed(seed)\ntf.random.set_seed(seed)\nos.environ['PYTHONHASHSEED'] = str(seed)\ntf.compat.v1.set_random_seed(seed)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"labels = ['Species1', # 1\n          'Species2', # 2\n          'Species3', # 3\n          'Species4', # 4\n          'Species5', # 5\n          'Species6', # 6\n          'Species7', # 7\n          'Species8', # 8\n]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_size_2D = (96, 96)\ninput_shape = (96, 96, 3)\nval_split = 0.2\n\nepochs = 200\nbatch_size = 8\nlr=1e-4\n\neffnet_freeze = 0\ndense_freeze = 0\nconvnext_freeze = 0","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_names = ['DenseNet', 'ConvNeXt']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Evaluation","metadata":{}},{"cell_type":"markdown","source":"### Performance","metadata":{}},{"cell_type":"code","source":"def evaluate_classes_performance(model, validation_dataset):\n\n    data_list = []\n    label_list = []\n    batch_index = 0\n\n    while batch_index <= validation_dataset.batch_index:\n        data = validation_dataset.next()\n\n        for i in range(len(data[0])):\n            data_list.append(data[0][i])\n            label_list.append(data[1][i])\n\n        batch_index = batch_index + 1\n\n    data_array = np.array(data_list)\n    label_array = np.array(label_list)   \n    label_values = np.argmax(label_array, axis=1)\n    predictions = tl_model.predict(data_array)\n    predictions = np.argmax(predictions, axis=1)\n    \n    report = classification_report(label_values, predictions)\n    print(report)\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Plots","metadata":{}},{"cell_type":"code","source":"def plot_acc_loss(history):\n    plt.figure(figsize=(20,5))\n    plt.plot(history['loss'], label='Training', alpha=.8, color='#ff7f0e')\n    plt.plot(history['val_loss'], label='Validation', alpha=.8, color='#4D61E2')\n    plt.legend(loc='upper left')\n    plt.title('Binary Crossentropy')\n    plt.grid(alpha=.3)\n\n    plt.figure(figsize=(20,5))\n    plt.plot(history['accuracy'], label='Training', alpha=.8, color='#ff7f0e')\n    plt.plot(history['val_accuracy'], label='Validation', alpha=.8, color='#4D61E2')\n    plt.legend(loc='upper left')\n    plt.title('Accuracy')\n    plt.grid(alpha=.3)\n\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":" def plot_double_acc_loss(history1, history2):\n    plt.figure(figsize=(15,5))\n    plt.plot(history1['loss'], label='Training 1', alpha=.3, color='#4D61E2', linestyle='--')\n    plt.plot(history1['val_loss'], label='Validation 1', alpha=.8, color='#4D61E2')\n    plt.plot(history2['loss'],  label='Training 2', alpha=.3, color='#2ABC3D', linestyle='--')\n    plt.plot(history2['val_loss'], label='Validation 2', alpha=.8, color='#2ABC3D')\n    plt.legend(loc='upper left')\n    plt.title('Categorical Crossentropy')\n    plt.grid(alpha=.3)\n\n    plt.figure(figsize=(15,5))\n    plt.plot(history1['accuracy'], label='Training 1', alpha=.3, color='#4D61E2', linestyle='--')\n    plt.plot(history1['val_accuracy'], label='Validation 1', alpha=.8, color='#4D61E2')\n    plt.plot(history2['accuracy'], label='Training 2', alpha=.3, color='#2ABC3D', linestyle='--')\n    plt.plot(history2['val_accuracy'], label='Validation 2', alpha=.8, color='#2ABC3D')\n    plt.legend(loc='upper left')\n    plt.title('Accuracy')\n    plt.grid(alpha=.3)\n\n    plt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Importing the dataset","metadata":{}},{"cell_type":"code","source":"# Augmented ImageDataGenerator\naug_train_data_gen = ImageDataGenerator(rotation_range=40, \n                                        fill_mode='reflect',\n                                        height_shift_range=40,\n                                        width_shift_range=30,\n                                        brightness_range=[0.5,1.3],\n                                        zoom_range=0.5,\n                                        vertical_flip=True,\n                                        horizontal_flip=True,\n                                        validation_split=val_split\n                                       )\n# Non-augmented ImageDataGenerator\nno_aug_data_gen = ImageDataGenerator(validation_split=val_split)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load training data (augmented and non-augmented) and validation data\naug_train_gen = aug_train_data_gen.flow_from_directory(directory=dataset_dir,\n                                               target_size=image_size_2D,\n                                               color_mode='rgb',\n                                               classes=labels,\n                                               subset=\"training\",\n                                               class_mode='categorical',\n                                               batch_size=batch_size,\n                                               shuffle=True,\n                                               seed=seed)\ntrain_gen = no_aug_data_gen.flow_from_directory(directory=dataset_dir,\n                                                target_size=image_size_2D,\n                                                color_mode='rgb',\n                                                classes=labels,\n                                                subset=\"training\",\n                                                class_mode='categorical',\n                                                batch_size=batch_size,\n                                                shuffle=True,\n                                                seed=seed)\nvalid_gen = no_aug_data_gen.flow_from_directory(directory=dataset_dir,\n                                                target_size=image_size_2D,\n                                                color_mode='rgb',\n                                                classes=labels,\n                                                subset=\"validation\",\n                                                class_mode='categorical',\n                                                batch_size=batch_size,\n                                                shuffle=False,\n                                                seed=seed)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## General model construction","metadata":{}},{"cell_type":"markdown","source":"### Model building","metadata":{}},{"cell_type":"code","source":"def compile_model(model, learning_rate):\n    model.compile(\n        loss=tfk.losses.CategoricalCrossentropy(),\n        optimizer=tfk.optimizers.Adam(learning_rate),\n        metrics='accuracy'\n    )\n    return model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def build_classifier_on_top(supernet, preprocessing_layer, name='model'):\n    # Input layer\n    inputs = tfk.Input(shape=input_shape, name='input')\n    # Preprocessing layer\n    x = preprocessing_layer(inputs)\n    # Supernet \n    x = supernet(x)\n    # GAP layer\n    x = tfkl.GlobalAveragePooling2D(name='GAP')(x)\n    # First hidden block\n    x = tfkl.Dropout(0.3, name='dropout_1', seed=seed)(x)\n    x = tfkl.Dense(\n        256, \n        activation='relu',\n        kernel_initializer = tfk.initializers.HeUniform(seed),\n        name='dense_1',\n    )(x)\n    # Second hidden block\n    x = tfkl.Dropout(0.3, name='dropout_2',seed=seed)(x)\n    x = tfkl.Dense(\n        256, \n        activation='relu',\n        kernel_initializer = tfk.initializers.HeUniform(seed),\n        name='dense_2',\n    )(x)\n    # Output block\n    x = tfkl.Dropout(0.3, name='dropout_3',seed=seed)(x)\n    outputs = tfkl.Dense(\n        8, \n        activation='softmax',\n        kernel_initializer = tfk.initializers.GlorotUniform(seed),\n        name='output',\n    )(x)\n    # Create and compile full model\n    model = tfk.Model(inputs=inputs, outputs=outputs, name=name)\n    model = compile_model(model, lr)\n    \n    return model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def build_model(base_net, freeze_count, preprocessing_layer, name):\n    # Import base net model\n    model_supernet = base_net(\n        include_top=False, # Do not include classifier\n        weights=\"imagenet\",\n        input_shape=input_shape\n    )\n\n    # Set all the layers of the base net as trainable\n    model_supernet.trainable = True\n    \n    # Freeze layers\n    for i, layer in enumerate(model_supernet.layers[:freeze_count]):\n        layer.trainable=False\n        \n    # Attach new classifier to base net\n    model = build_classifier_on_top(\n        model_supernet,\n        preprocessing_layer,\n        name=name,\n    )\n    \n    return model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Callbacks","metadata":{}},{"cell_type":"code","source":"def define_callbacks():\n    callbacks = []\n    # Early stopping callback\n    es_callback = tfk.callbacks.EarlyStopping(\n        monitor='val_accuracy',\n        mode='max',\n        patience=10,\n        restore_best_weights=True,\n    )\n    callbacks.append(es_callback)\n    # Other callbacks ...\n    return callbacks","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# EfficientNet Model","metadata":{}},{"cell_type":"markdown","source":"### Model creation","metadata":{}},{"cell_type":"code","source":"effnet_model = build_model(\n    tfk.applications.EfficientNetB7,\n    effnet_freeze,\n    tfk.applications.efficientnet.preprocess_input,\n    'effnet_model',\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"effnet_model.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### First training","metadata":{}},{"cell_type":"code","source":"# Fine tune the model\neffnet_history_1 = effnet_model.fit(\n    x = aug_train_gen,\n    validation_data = valid_gen,\n    epochs = epochs,\n    callbacks = define_callbacks(),\n).history","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot training history\nplot_acc_loss(effnet_history_1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Model editing","metadata":{}},{"cell_type":"code","source":"# Use the supernet with the fine-tuned weights only as feature extractor\neffnet_model.get_layer('efficientnetb7').trainable = False\n\n# Recompile the model\neffnet_model = compile_model(effnet_model, lr)\n\neffnet_model.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Second training","metadata":{}},{"cell_type":"code","source":"# Train the classifier on non-augmented training data\neffnet_history_2 = effnet_model.fit(\n    x = train_gen,\n    epochs = epochs,\n    validation_data = valid_gen,\n    callbacks = define_callbacks(),\n).history","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot training history\nplot_double_acc_loss(effnet_history_1, effnet_history_2)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Performance","metadata":{}},{"cell_type":"code","source":"# Evaluate the performance scores for the model on the validation dataset \nevaluate_classes_performance(effnet_model, valid_gen)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# DenseNet Model","metadata":{}},{"cell_type":"markdown","source":"### Model creation","metadata":{}},{"cell_type":"code","source":"dense_model = build_model(\n    tfk.applications.DenseNet201,\n    dense_freeze,\n    tfk.applications.densenet.preprocess_input,\n    'densenet_model',\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dense_model.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### First training","metadata":{}},{"cell_type":"code","source":"# Fine tune the model\ndense_history_1 = dense_model.fit(\n    x = aug_train_gen,\n    validation_data = valid_gen,\n    epochs = epochs,\n    callbacks = define_callbacks(),\n).history","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot training history\nplot_acc_loss(dense_history_1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Model editing","metadata":{}},{"cell_type":"code","source":"# Use the supernet with the fine-tuned weights only as feature extractor\ndense_model.get_layer('densenet201').trainable = False\n\n# Recompile the model\ndense_model = compile_model(dense_model, lr)\n\ndense_model.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Second training","metadata":{}},{"cell_type":"code","source":"# Train the classifier on non-augmented training data\ndense_history_2 = dense_model.fit(\n    x = train_gen,\n    epochs = epochs,\n    validation_data = valid_gen,\n    callbacks = define_callbacks(),\n).history","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot training history\nplot_double_acc_loss(dense_history_1, dense_history_2)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Performance","metadata":{}},{"cell_type":"code","source":"# Evaluate the performance scores for the model on the validation dataset \nevaluate_classes_performance(dense_model, valid_gen)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# ConvNeXt Model","metadata":{}},{"cell_type":"markdown","source":"### Model building","metadata":{}},{"cell_type":"code","source":"dense_model = build_model(\n    tfk.applications.ConvNeXtTiny,\n    convnext_freeze,\n    tfk.applications.convnext.preprocess_input,\n    'convnext_model',\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"convnext_model.summary()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### First training","metadata":{}},{"cell_type":"code","source":"# Fine tune the model\nconvnext_history_1 = convnext_model.fit(\n    x = aug_train_gen,\n    validation_data = valid_gen,\n    epochs = epochs,\n    callbacks = define_callbacks(),\n).history","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot training history\nplot_acc_loss(convnext_history_1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Model editing","metadata":{}},{"cell_type":"code","source":"# Use the supernet with the fine-tuned weights only as feature extractor\nconvnext_model.get_layer('convnext_tiny').trainable = False\n\n# Recompile the model\nconvnext_model = model_compile(convnext_model, lr)\n\nconvnext_model.summary()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Second training","metadata":{}},{"cell_type":"code","source":"# Train the classifier on non-augmented training data\nconvnext_history_1 = convnext_model.fit(\n    x = train_gen,\n    epochs = epochs,\n    validation_data = valid_gen,\n    callbacks = define_callbacks(),\n).history","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot training history\nplot_double_acc_loss(convnext_history_1, convnext_history_2)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Performance","metadata":{}},{"cell_type":"code","source":"# Evaluate the performance scores for the model on the validation dataset \nevaluate_classes_performance(convnext_model, valid_gen)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Ensemble Model","metadata":{}},{"cell_type":"markdown","source":"### Loading the submodels","metadata":{}},{"cell_type":"code","source":"def load_all_models(model_names):\n    all_models = []\n    for model_name in model_names:\n        filename = os.path.join(submodels_dir, model_name)\n        model = tfk.models.load_model(filename)\n        all_models.append(model)\n        print('Successfully loaded submodule:', filename)\n        evaluate_classes_performance(model, valid_gen)\n    return all_models","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Loading the submodels from existing saves\n# submodels = load_all_models(model_names)\n\n# Loading the submodels from in-notebook trained models\nsubmodels = [dense_model, convnext_model]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Standardize model names and make them non-trainable\nfor i, model in enumerate(submodels):\n    model._name = f\"model_{i}\"\n    for layer in model.layers:\n        layer.trainable = False","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Build ensemble model","metadata":{}},{"cell_type":"code","source":"# Common input layer\ninput_layer = tfk.Input(shape=input_shape)\n# Disaggregated submodel outputs\nsubmodel_outputs = [model(input_layer) for model in submodels]\n# Aggregate submodel outputs by concatenation\nx = tfkl.concatenate(submodel_outputs)\n# Hidden layer\nx = tfkl.Dense(\n    10, \n    activation='relu',\n    kernel_initializer = tfk.initializers.HeUniform(seed),\n    name='hidden_dense',\n)(x)\n# Output layer\nensemble_output = tfkl.Dense(\n    8, \n    activation='softmax', \n    kernel_initializer = tfk.initializers.GlorotUniform(seed),\n    name='ensemble_output',\n)(x)\n# Create and compile ensemble model\nens_model = tfk.Model(inputs=input_layer, outputs=ensemble_output, name='ens_model')\nens_model = compile_model(ens_model, learning_rate=1e-3)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ens_model.summary()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Ensemble training","metadata":{}},{"cell_type":"code","source":"ens_history = ens_model.fit(\n    x=aug_train_gen,\n    epochs=epochs, \n    validation_data=valid_gen,\n    callbacks = define_callbacks(),\n).history","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot the training\nplot_acc_loss(ens_history)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Performance","metadata":{}},{"cell_type":"code","source":"evaluate_classes_performance(ens_model, valid_gen)","metadata":{},"execution_count":null,"outputs":[]}]}