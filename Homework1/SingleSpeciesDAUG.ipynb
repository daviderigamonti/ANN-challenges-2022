{"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"provenance":[]},"gpuClass":"standard","kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"### Connect to Drive","metadata":{"id":"omSLbdLvhDRx"}},{"cell_type":"code","source":"#from google.colab import drive\n#drive.mount('/gdrive')","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":25852,"status":"ok","timestamp":1668430728427,"user":{"displayName":"Ri ga","userId":"15539171450533002544"},"user_tz":-60},"id":"AoaLQpvChLpb","outputId":"158aedd8-4086-4dce-cfa7-7fe629a46a87","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#%cd /gdrive/My Drive/ANN Exercises/Homework1","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1668430985019,"user":{"displayName":"Ri ga","userId":"15539171450533002544"},"user_tz":-60},"id":"2ItZ794FhPQe","outputId":"c389da83-45eb-457b-f20a-da32be16a507","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Import libraries","metadata":{"id":"MdD_8Vyswkwf"}},{"cell_type":"code","source":"!pip install -U tensorflow==2.10.0\n\nimport tensorflow as tf\nimport numpy as np\nimport os\nimport random\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\nfrom sklearn.metrics import confusion_matrix\n\ntfk = tf.keras\ntfkl = tf.keras.layers\nprint(tf.__version__)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3788,"status":"ok","timestamp":1668430737314,"user":{"displayName":"Ri ga","userId":"15539171450533002544"},"user_tz":-60},"id":"f_sOaV1Y8NsL","outputId":"6ec72cfa-4896-4a23-8df2-5f80425b893e","execution":{"iopub.status.busy":"2022-11-17T01:26:09.312896Z","iopub.execute_input":"2022-11-17T01:26:09.313290Z","iopub.status.idle":"2022-11-17T01:26:24.185929Z","shell.execute_reply.started":"2022-11-17T01:26:09.313202Z","shell.execute_reply":"2022-11-17T01:26:24.184006Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: tensorflow==2.10.0 in /opt/conda/lib/python3.7/site-packages (2.10.0)\nRequirement already satisfied: wrapt>=1.11.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.10.0) (1.12.1)\nRequirement already satisfied: keras-preprocessing>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.10.0) (1.1.2)\nRequirement already satisfied: tensorflow-estimator<2.11,>=2.10.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.10.0) (2.10.0)\nRequirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.10.0) (1.6.3)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.10.0) (59.8.0)\nRequirement already satisfied: flatbuffers>=2.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.10.0) (22.10.26)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.10.0) (1.43.0)\nRequirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.10.0) (1.3.0)\nRequirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.10.0) (3.3.0)\nRequirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.10.0) (4.4.0)\nRequirement already satisfied: protobuf<3.20,>=3.9.2 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.10.0) (3.19.4)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.10.0) (21.3)\nRequirement already satisfied: keras<2.11,>=2.10.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.10.0) (2.10.0)\nRequirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.10.0) (1.15.0)\nRequirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.10.0) (0.2.0)\nRequirement already satisfied: numpy>=1.20 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.10.0) (1.21.6)\nRequirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.10.0) (3.7.0)\nRequirement already satisfied: gast<=0.4.0,>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.10.0) (0.4.0)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.10.0) (0.27.0)\nRequirement already satisfied: tensorboard<2.11,>=2.10 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.10.0) (2.10.1)\nRequirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.10.0) (14.0.6)\nRequirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.7/site-packages (from tensorflow==2.10.0) (1.1.0)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.7/site-packages (from astunparse>=1.6.0->tensorflow==2.10.0) (0.37.1)\nRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.0) (2.2.2)\nRequirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.0) (2.28.1)\nRequirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.0) (1.8.1)\nRequirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.0) (1.35.0)\nRequirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.0) (0.6.1)\nRequirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.0) (0.4.6)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.7/site-packages (from tensorboard<2.11,>=2.10->tensorflow==2.10.0) (3.3.7)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.7/site-packages (from packaging->tensorflow==2.10.0) (3.0.9)\nRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (4.8)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (0.2.7)\nRequirement already satisfied: cachetools<5.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (4.2.4)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.7/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (1.3.1)\nRequirement already satisfied: importlib-metadata>=4.4 in /opt/conda/lib/python3.7/site-packages (from markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (4.13.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (3.3)\nRequirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (2.1.0)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (2022.9.24)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (1.26.12)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.7/site-packages (from werkzeug>=1.0.1->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (2.1.1)\nRequirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.7/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (3.8.0)\nRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.7/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (0.4.8)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow==2.10.0) (3.2.0)\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n\u001b[0m","output_type":"stream"},{"name":"stderr","text":"2022-11-17 01:26:19.179722: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\nTo enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n2022-11-17 01:26:19.349067: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda/lib:/usr/local/lib/x86_64-linux-gnu:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:\n2022-11-17 01:26:19.349113: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n2022-11-17 01:26:19.374735: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n2022-11-17 01:26:20.587610: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda/lib:/usr/local/lib/x86_64-linux-gnu:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:\n2022-11-17 01:26:20.587828: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda/lib:/usr/local/lib/x86_64-linux-gnu:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:\n2022-11-17 01:26:20.587842: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n","output_type":"stream"},{"name":"stdout","text":"2.10.0\n","output_type":"stream"}]},{"cell_type":"code","source":"# Import dataset\n#!unzip training_dataset_homework1.zip\n\n# Dataset folders \ndataset_dir = '../input/homework1/training_data_final'","metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1668430891828,"user":{"displayName":"Ri ga","userId":"15539171450533002544"},"user_tz":-60},"id":"f6CWlKBVoi7s","execution":{"iopub.status.busy":"2022-11-17T01:26:32.028789Z","iopub.execute_input":"2022-11-17T01:26:32.029611Z","iopub.status.idle":"2022-11-17T01:26:32.036472Z","shell.execute_reply.started":"2022-11-17T01:26:32.029572Z","shell.execute_reply":"2022-11-17T01:26:32.034810Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# Random seed for reproducibility\nseed = 1337\n\nrandom.seed(seed)\nnp.random.seed(seed)\ntf.random.set_seed(seed)\nos.environ['PYTHONHASHSEED'] = str(seed)\ntf.compat.v1.set_random_seed(seed)","metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1668430895313,"user":{"displayName":"Ri ga","userId":"15539171450533002544"},"user_tz":-60},"id":"s8aWwo1fs3Zh","execution":{"iopub.status.busy":"2022-11-17T01:26:37.977188Z","iopub.execute_input":"2022-11-17T01:26:37.977719Z","iopub.status.idle":"2022-11-17T01:26:37.984888Z","shell.execute_reply.started":"2022-11-17T01:26:37.977676Z","shell.execute_reply":"2022-11-17T01:26:37.983714Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"labels = ['Species1', # 1\n          'Species2', # 2\n          'Species3', # 3\n          'Species4', # 4\n          'Species5', # 5\n          'Species6', # 6\n          'Species7', # 7\n          'Species8', # 8\n]","metadata":{"executionInfo":{"elapsed":6,"status":"ok","timestamp":1668430898832,"user":{"displayName":"Ri ga","userId":"15539171450533002544"},"user_tz":-60},"id":"xqGEPTXRvg4q","execution":{"iopub.status.busy":"2022-11-17T01:26:40.158313Z","iopub.execute_input":"2022-11-17T01:26:40.158737Z","iopub.status.idle":"2022-11-17T01:26:40.164396Z","shell.execute_reply.started":"2022-11-17T01:26:40.158703Z","shell.execute_reply":"2022-11-17T01:26:40.162976Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"# Images are divided into folders, one for each class. \n# If the images are organized in such a way, we can exploit the \n# ImageDataGenerator to read them from disk.\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator","metadata":{"execution":{"iopub.status.busy":"2022-11-17T01:26:41.790266Z","iopub.execute_input":"2022-11-17T01:26:41.790697Z","iopub.status.idle":"2022-11-17T01:26:41.798890Z","shell.execute_reply.started":"2022-11-17T01:26:41.790661Z","shell.execute_reply":"2022-11-17T01:26:41.797445Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"def generate_new_class_samples(\n    label_idx,                            # species to target as index of \"labels\" array\n    output_dir=dataset_dir+'_augmented',\n    n_images=1,                           # number of images to save\n    one_aug=True,                         # perform one type of augmentation per image or multiple\n    shuffle=False,                        # order of image retrieval\n    hflip=False,                          # horizontal flip (True, False)\n    vflip=False,                          # vertical flip(True, False)\n    contrast=None,                        # contrast ([lower, upper])\n    saturation=None,                      # saturation ([lower, upper]) \n    brightness=None,                      # brightness factor -1.0-1.0 ([lower, upper])\n    rotation=None,                        # rotation factor as fraction of 2*PI ([lower, upper])\n    rotation_fill_mode='nearest',         # fill mode for rotation {\"constant\", \"reflect\", \"wrap\", \"nearest\"})\n    translation=None,                     # translation factors ([[height_lower, height_upper], [width_lower, width_upper]])\n    translation_fill_mode='nearest',      # fill mode for translation {\"constant\", \"reflect\", \"wrap\", \"nearest\"})\n    zoom=None,                            # zoom factors ([[height_lower, height_upper], [width_lower, width_upper]])\n    zoom_fill_mode='nearest',             # fill mode for zoom {\"constant\", \"reflect\", \"wrap\", \"nearest\"})\n    seed=None,\n):\n\n    def augment_all(image):\n        if hflip:\n            image = tf.image.random_flip_left_right(image, seed)\n        if vflip:\n            image = tf.image.random_flip_up_down(image, seed)\n        if contrast and len(contrast) == 2:\n            image = tf.image.random_contrast(image, lower=contrast[0], upper=contrast[1], seed=seed)\n        if saturation and len(saturation) == 2:\n            image = tf.image.random_saturation(image, lower=saturation[0], upper=saturation[1], seed=seed)\n        if brightness:\n            seq = tfk.Sequential([\n                tfkl.RandomBrightness(factor=brightness, seed=seed)])\n            image = seq(tf.expand_dims(image, 0), training=True)\n        if rotation and rotation_fill_mode:\n            seq = tfk.Sequential([\n                tfkl.preprocessing.RandomRotation(rotation, fill_mode=rotation_fill_mode, seed=seed)])\n            image = seq(tf.expand_dims(image, 0), training=True)\n        if translation and translation_fill_mode:\n            seq = tfk.Sequential([\n                tfkl.experimental.preprocessing.RandomTranslation(\n                    translation[0], translation[1], fill_mode=translation_fill_mode, seed=seed)])\n            image = seq(tf.expand_dims(image, 0), training=True)\n        if zoom and zoom_fill_mode:\n            seq = tfk.Sequential([\n                tfkl.experimental.preprocessing.RandomZoom(\n                    height_factor=zoom[0], width_factor=zoom[1], fill_mode=zoom_fill_mode, seed=seed)])\n            image = seq(tf.expand_dims(image, 0), training=True)\n        return image\n    \n    def augment_one(image):\n        images = []\n        if hflip:\n            images.append(tf.image.random_flip_left_right(image, seed))\n        if vflip:\n            images.append(tf.image.random_flip_up_down(image, seed))\n        if contrast and len(contrast) == 2:\n            images.append(tf.image.random_contrast(image, lower=contrast[0], upper=contrast[1], seed=seed))\n        if saturation and len(saturation) == 2:\n            images.append(tf.image.random_saturation(image, lower=saturation[0], upper=saturation[1], seed=seed))\n        if brightness:\n            seq = tfk.Sequential([\n                tfkl.RandomBrightness(factor=brightness, seed=seed)])\n            image = seq(tf.expand_dims(image, 0), training=True)\n        if rotation and rotation_fill_mode:\n            seq = tfk.Sequential([\n                tfkl.experimental.preprocessing.RandomRotation(rotation, fill_mode=rotation_fill_mode, seed=seed)])\n            image = seq(tf.expand_dims(image, 0), training=True)\n        if translation and translation_fill_mode:\n            seq = tfk.Sequential([\n                tfkl.experimental.preprocessing.RandomTranslation(\n                    translation[0], translation[1], fill_mode=translation_fill_mode, seed=seed)])\n            image = seq(tf.expand_dims(image, 0), training=True)\n        if zoom and zoom_fill_mode:\n            seq = tfk.Sequential([\n                tfkl.experimental.preprocessing.RandomZoom(\n                    height_factor=zoom[0], width_factor=zoom[1], fill_mode=zoom_fill_mode, seed=seed)])\n            image = seq(tf.expand_dims(image, 0), training=True)\n        return images[random.randrange(len(images))]\n    \n    if one_aug:\n        class_aug_data_gen = ImageDataGenerator(preprocessing_function=augment_one)\n    else:\n         class_aug_data_gen = ImageDataGenerator(preprocessing_function=augment_all)\n    class_aug_gen = class_aug_data_gen.flow_from_directory(\n        directory=dataset_dir,\n        target_size=(96,96),\n        color_mode='rgb',\n        classes=[labels[label_idx]],\n        class_mode='categorical',\n        batch_size=1,\n        shuffle=shuffle,\n        save_to_dir=output_dir,\n        save_prefix='aug',\n        seed=seed,\n    )\n    \n    for i, batch in enumerate(class_aug_gen):\n        if i >= n_images-1:\n            break ","metadata":{"execution":{"iopub.status.busy":"2022-11-17T01:26:43.500788Z","iopub.execute_input":"2022-11-17T01:26:43.501191Z","iopub.status.idle":"2022-11-17T01:26:43.523453Z","shell.execute_reply.started":"2022-11-17T01:26:43.501157Z","shell.execute_reply":"2022-11-17T01:26:43.522566Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# Generating extra sample for Species 1\ngenerate_new_class_samples(\n    0, \n    '/kaggle/working/', \n    one_aug=False, \n    #zoom=[[0.1, 0.2], 0], \n    brightness=[-0.3, 0.4],\n    seed=seed,\n)","metadata":{"execution":{"iopub.status.busy":"2022-11-17T01:28:34.848820Z","iopub.execute_input":"2022-11-17T01:28:34.849214Z","iopub.status.idle":"2022-11-17T01:28:35.548559Z","shell.execute_reply.started":"2022-11-17T01:28:34.849179Z","shell.execute_reply":"2022-11-17T01:28:35.546783Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Found 186 images belonging to 1 classes.\n","output_type":"stream"}]},{"cell_type":"code","source":"# Create an instance of ImageDataGenerator for training, validation, and test sets\ntrain_data_gen = ImageDataGenerator(\n        validation_split=0.15, \n        rescale=1/255.,\n)\n\n# Obtain a data generator with the 'ImageDataGenerator.flow_from_directory' method\ntrain_gen = train_data_gen.flow_from_directory(directory=dataset_dir,\n                                               target_size=(96,96),\n                                               color_mode='rgb',\n                                               classes=labels, # can be set to labels\n                                               subset=\"training\",\n                                               class_mode='categorical',\n                                               batch_size=64,\n                                               shuffle=True,\n                                               seed=seed)\nvalid_gen = train_data_gen.flow_from_directory(directory=dataset_dir,\n                                               target_size=(96,96),\n                                               color_mode='rgb',\n                                               classes=labels, # can be set to labels\n                                               subset=\"validation\",\n                                               class_mode='categorical',\n                                               batch_size=64,\n                                               shuffle=False,\n                                               seed=seed)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":8811,"status":"ok","timestamp":1668430999554,"user":{"displayName":"Ri ga","userId":"15539171450533002544"},"user_tz":-60},"id":"IUE2a88jpS3-","outputId":"4e44134e-d52b-4975-ab1a-9dbddbfbc723","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Assigned labels\")\nprint(train_gen.class_indices)\nprint()\nprint(\"Target classes\")\nprint(train_gen.classes)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":10,"status":"ok","timestamp":1668430775722,"user":{"displayName":"Ri ga","userId":"15539171450533002544"},"user_tz":-60},"id":"9ahtrx9uvHAu","outputId":"67b65a01-55dc-4dc9-bd7b-2d40a0a799d3","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def get_next_batch(generator):\n    batch = next(generator)\n\n    image = batch[0]\n    target = batch[1]\n    \n    print(\"(Input) image shape:\", image.shape)\n    print(\"Target shape:\",target.shape)\n\n    # Visualize only the first sample\n    image = image[0]\n    target = target[0]\n    target_idx = np.argmax(target)\n    print()\n    print(\"Categorical label:\", target)\n    print(\"Label:\", target_idx)\n    print(\"Class name:\", labels[target_idx])\n    fig = plt.figure(figsize=(6, 4))\n    \n    image = image*255\n    \n    plt.imshow(np.uint8(image))\n\n    return batch","metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1668430778812,"user":{"displayName":"Ri ga","userId":"15539171450533002544"},"user_tz":-60},"id":"VjnPdLbwvL7b","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get a sample from dataset and show info\n_ = get_next_batch(valid_gen)","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":377},"executionInfo":{"elapsed":6064,"status":"ok","timestamp":1668431013399,"user":{"displayName":"Ri ga","userId":"15539171450533002544"},"user_tz":-60},"id":"gij6IfU6vPHV","outputId":"ad656e2e-6a34-42b5-b657-c59c4e41a61d","trusted":true},"execution_count":null,"outputs":[]}]}